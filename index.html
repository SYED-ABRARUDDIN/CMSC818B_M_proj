<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resilient Distributed Coordination of Multi-Robot Systems</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Graph Neural Network-based Multi-agent Reinforcement Learning</h1>
        <h2>Resilient Distributed Coordination of Multi-Robot Systems</h2>
    </header>
    <section id="introduction">
        <h2>Introduction</h2>
        <math> \zeta_{max} = \max_{v \in V} \zeta(v) </math>
        <p>
        Multi-agent systems are at the forefront of evolving industrial environments and emergency response scenarios, where multiple robots or agents must work cohesively to achieve common goals. </p>
        <p> Here we focus on solving the benchmark problem of the multirobot patrolling problem. In the patrolling problem, agents must repeatedly visit a set of observation points or nodes, attempting to minimize one of several metrics such as, the average idleness time</p>
        <math>\zeta = \frac{1}{m} \sum_{v \in V} \zeta(v) </math>
           <p> or the worst node idleness time </p>
        <math> \zeta_{max} = \max_{v \in V} \zeta(v) </math>
        
 </section>

    
    <section id="methodology">
        <h2>Methodology</h2>

        <p>The approach used is to use Multi-Agent Graph Embedding-based Coordination (MAGEC) based on a MARL** algorithm designed for resilient distributed coordination of multi-robot systems, particularly in scenarios prone to disturbances like agent attrition and partial observability.
MAGEC leverages graph neural networks (GNNs) and multi-agent proximal policy optimization (MAPPO) to enable robust coordination. MAGEC uses an actor-critic architecture, with a custom k-convolution GNN serving as the actor. Given graph-based inputs, the actor must select an edge of the graph for the agent to traverse next.</</p>
        <h3>MAGEC Algorithm</h3>
        <p>MAGEC leverages a sophisticated algorithm designed to enhance the resilience and efficiency of multi-agent systems. At its core, MAGEC utilizes GNNs to process and analyze graph-based data representing operational environments, enabling a deeper understanding of complex agent interactions and environmental dynamics. This understanding is critical in optimizing agent decision-making and actions based on the global objectives set within the system.</p>
    
        <h3>Role of GNNs</h3>
        <p>Graph Neural Networks play a pivotal role in MAGEC by enabling the system to model and interpret the vast networks of relationships and interactions between agents and their operational environments. GNNs excel in capturing the structural nuances of these networks, processing node and edge data to generate embeddings that encapsulate the essential features necessary for informed decision-making. These capabilities are particularly beneficial in scenarios where environmental conditions are continuously changing and agent configurations are dynamically adjusted.</p>
    
        <h3>Training and Simulation</h3>
        <p>The training of the MAGEC system is conducted using a ROS 2-based simulator, which provides a realistic and flexible platform for testing and development. This simulator allows for the emulation of real-world disturbances such as agent attrition and communication failures, enabling researchers to fine-tune the MAGEC algorithm under controlled yet challenging conditions. Through iterative simulations, MAGEC is rigorously trained to adapt and respond effectively to a range of operational disruptions, thereby ensuring that the system remains robust and reliable even under adverse conditions.</p>
    </section>
    <section id="design-methodology">
        <h2>Design Methodology</h2>
        <p>The design of the MAGEC system is a testament to innovative engineering, blending traditional reinforcement learning structures with cutting-edge graph neural network technology to address complex multi-agent coordination challenges effectively.</p>


        <p> Why GNNs? \\

        Many real-world environments and problems, such as road networks, forests, and warehouses, can be naturally represented as graphs. **GNNs**, with their ability to learn embeddings of graphs by aggregating information from nodes and edges, are well-suited for modeling and analyzing such environments. They can capture the attributes of individual entities and the complex relationships between them, making them a natural fit for multi-agent coordination tasks.</p>
        
        
        <h3>MAGEC Architecture </h3>

        <p>MAGEC employs an actor-critic architecture, trained entirely through the MAPPO algorithm. This architecture enables distributed coordination among agents while optimizing for global objectives.</p>

        <ul>
                    <li>
                <figure>
                    <img src="images/MAGEC training architecture.png" alt="Graph showing MAGEC performance in communication-limited scenarios" style="width:50%;">
                    <figcaption>Figure 7: This graph demonstrates how MAGEC performs in scenarios with limited communication. Even with reduced communication success rates, MAGEC outperforms other methods, showcasing its capability to function effectively under communication constraints.</figcaption>
                </figure>
            </li>
        </ul>

        
            <p>Centralized Training, Decentralized Execution (CTDE): MAGEC uses a shared critic and policy during training, enabling optimization based on global objectives. After training, only the actor network is used for execution, allowing decentralized coordination. </p>
            <p> Critic Network: The critic network is a simple multi-layer perceptron (MLP) that takes global information, like node idleness times and an adjacency matrix, to estimate the value of the current state. </p>
            <p>Actor Network: The actor network is more complex, utilizing a custom k-convolution GNN. It receives graph-based observations, performs neighbor scoring using an MLP, and finally selects an action (edge to traverse) based on the output of another "selector" MLP. </p>
            <p>Discrete Wayfinding:MAGEC enables agents to navigate the graph environment by assigning identifiers to neighboring nodes, enforcing an order for action selection. </p>
            <p>Graph Neural Network Design:The GNN used in MAGEC is based on the GraphSAGE algorithm but modified to consider edge attributes, which are crucial for wayfinding. It utilizes a k-hop message passing mechanism with skip connections for efficient training and embedding of large graphs.  </p>
            <p>Neighbor Scoring: To select the best edge to traverse, MAGEC employs a "neighbor scoring" strategy, where graph embeddings of neighboring nodes are processed by an MLP to generate scores, which are then used by the selector MLP to determine the action. </p>
            <p>Training Environment: The training environment utilizes graph-based observations, where agents perceive node and edge features within a limited radius. Rewards are given both locally (for visiting nodes) and globally (at the end of each episode) to optimize for minimizing average node idleness time. </p>
            <p>Training Algorithm: A modified MAPPO algorithm is used for training, adapted to handle sparse rewards and actions inherent in the patrolling problem. This involves skipping time steps when actions are not required, reducing the number of samples stored and speeding up training. </p>
            <p>Execution: After training, the learned policy is directly applied to agents during execution, enabling them to select actions based on their local observations.</p>
            









        <ul>
                    <li>
                <figure>
                    <img src="images/GNN computing node embeddings.png" alt="Graph showing MAGEC performance in communication-limited scenarios" style="width:50%;">
                    <figcaption>Figure 7: This graph demonstrates how MAGEC performs in scenarios with limited communication. Even with reduced communication success rates, MAGEC outperforms other methods, showcasing its capability to function effectively under communication constraints.</figcaption>
                </figure>
            </li>
        </ul>
        
        <h3>System Architecture</h3>
        <p>The architecture of MAGEC is built on a robust actor-critic framework, where the 'actor' and 'critic' components play distinct yet complementary roles. The actor component is responsible for making decisions based on the policy derived from the current state, whereas the critic evaluates the action taken by the actor by computing the potential reward. This separation enhances the system’s ability to learn and adapt from each action's consequences, optimizing both the decision-making process and the subsequent outcomes in dynamic environments.</p>
    
        <h3>Graph Neural Network Design</h3>
        <p>The Graph Neural Network (GNN) within MAGEC is specifically tailored to support the unique requirements of multi-agent environments. Key adaptations have been made to the traditional GraphSAGE algorithm to better handle edge attributes, which are critical in pathfinding and navigating complex network topologies. These modifications allow the GNN to incorporate both node and edge data effectively, enabling a richer representation of the environment that aids in more accurate and informed decision-making processes.</p>
    
        <h3>Neighbor Scoring</h3>
        <p>Neighbor scoring is a pivotal feature of MAGEC's GNN architecture, allowing the system to evaluate and rank potential actions based on the utility of each neighbor in the graph. This process involves calculating a score for each neighboring node that reflects its suitability for achieving the system's objectives, considering factors such as proximity, connectivity, and past interactions. The scores inform the actor’s decisions, ensuring that actions are not just reactive but are strategically aligned with the system’s overall goals.</p>
    </section>
       
    <section id="conclusion">
        <h2>Conclusion</h2>
        <p>MAGEC demonstrates the potential of GNN-based MARL for robust multi-robot coordination in graph environments.  Its resilience to agent attrition and partial observability make it a better approach for real-world applications.
        </p></section>
    
    <section id="references">
        <h2>References</h2>
        <p>The following works provide foundational insights and methodologies that have influenced the development of the MAGEC system:</p>
        <ul>
            <li>Yu, C., Velu, A., Vinitsky, E., Gao, J., Wang, Y., Bayen, A., & Wu, Y. (2022). The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games. </li>
            <li>Goeckner, A., Sui, Y., Martinet, N., Li, X., & Zhu, Q. (2023). Graph Neural Network-based Multi-agent Reinforcement Learning for Resilient Distributed Coordination of Multi-Robot Systems.</li>
            
    </section>
    
    <footer>
        <p>Developed by Abraruddin Syed and Shivam Dhakad.</p>
    </footer>
</body>
</html>
